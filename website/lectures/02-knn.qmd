---
title: "Lecture 2: k-Nearest Neighbors"
subtitle: "Framing Prediction Problems & Instance-Based Learning"
---

## Overview

In this hands-on lecture, we tackle a real problem: **finding compatible ML project teammates** using k-Nearest Neighbors. Yes, you'll actually use this system to form your project teams! We'll explore how to frame real-world problems as ML tasks, understand the elegance of lazy learning, and confront the challenges of high-dimensional spaces.

## Learning Objectives

By the end of this lecture, you will:

- **Frame** real-world problems as ML tasks with inputs (X) and outputs (y)
- **Apply** k-NN for classification and regression tasks
- **Analyze** the impact of distance metrics and feature scaling
- **Understand** the curse of dimensionality and its practical implications
- **Design** fair and effective matching systems with domain constraints
- **Evaluate** trade-offs between different similarity measures

## Materials

:::{.callout-tip}
## Quick Access
**[Lecture Notebook](https://github.com/jinming99/learn-ml-by-building/blob/main/Lecture%202%20KNN/02-KNN.ipynb)**  
**[Open in Colab](https://colab.research.google.com/github/jinming99/learn-ml-by-building/blob/main/Lecture%202%20KNN/02-KNN.ipynb)**  
**[Lecture Folder](https://github.com/jinming99/learn-ml-by-building/tree/main/Lecture%202%20KNN)**
:::

:::{.callout-important collapse=false}
## Pre-Class Requirements
Complete the [Project Matchmaker Form](https://docs.google.com/forms/d/e/1FAIpQLSfx5iz7JF3ePe1-c-HkKMlxiUICjjog9D89YGy5VtqfhUFu_g/viewform?usp=sharing&ouid=116115729328867711828) by Mon 8/26, 12:00 PM ET. Required for [Lecture 2: k-NN](02-knn.qmd); counts toward participation.
:::

## Interactive Demo

:::{.callout-note}
## üéÆ Team Matcher Visualization
Experience k-NN in action with our **[Interactive Team Matching Demo](../project-matchmaker/)**

This real-time visualization lets you:

- Adjust k parameter and see immediate effects
- Explore different dimension pairs 
- View how proximity translates to similarity
- Discover natural clustering patterns in the class
:::

## Key Topics

1. **The Data Journey**: From text surveys ‚Üí NLP features ‚Üí 8D vectors
2. **k-NN Fundamentals**: The beautiful simplicity of "you are your neighbors"
3. **Distance Metrics**: Euclidean, Manhattan, Cosine, and when each matters
4. **Curse of Dimensionality**: When all points become equidistant
5. **Fairness in ML**: Ensuring inclusive team formation

## Additional Resources

- [Scikit-learn k-NN Documentation](https://scikit-learn.org/stable/modules/neighbors.html)


---

**Previous**: [‚Üê Lecture 1: Welcome to ML](01-overview.qmd) | **Next**: [Lecture 3: Linear Regression ‚Üí](03-linear.qmd)